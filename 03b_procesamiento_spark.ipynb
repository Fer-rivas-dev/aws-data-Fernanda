{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007966df-1de7-4e3e-b8ce-bf83374791d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports completados\n",
      "ğŸ“… 2025-10-17 19:41:37\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# NOTEBOOK 03b: PROCESAMIENTO CON SPARK\n",
    "# Disney Data Pipeline - Fase 3\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError, NoCredentialsError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Imports completados\")\n",
    "print(f\"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18136635-fda7-4205-91f3-5855327e5ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Verificando configuraciÃ³n:\n",
      "\n",
      "âœ… AWS Access Key       : AKIA...63PU\n",
      "âœ… AWS Secret Key       : mNaj...3rkr\n",
      "âœ… AWS Region           : us-west-1\n",
      "âœ… S3 Bucket            : xideralaws-curso-fernanda\n",
      "\n",
      "âœ… Variables configuradas correctamente\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 2: CARGAR VARIABLES DE AMBIENTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "required = {\n",
    "    'AWS_ACCESS_KEY_ID': 'AWS Access Key',\n",
    "    'AWS_SECRET_ACCESS_KEY': 'AWS Secret Key',\n",
    "    'AWS_DEFAULT_REGION': 'AWS Region',\n",
    "    'S3_BUCKET_NAME': 'S3 Bucket'\n",
    "}\n",
    "\n",
    "print(\"ğŸ” Verificando configuraciÃ³n:\\n\")\n",
    "missing = []\n",
    "\n",
    "for var, desc in required.items():\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        masked = f\"{value[:4]}...{value[-4:]}\" if 'KEY' in var else value\n",
    "        print(f\"âœ… {desc:20} : {masked}\")\n",
    "    else:\n",
    "        print(f\"âŒ {desc:20} : NO CONFIGURADA\")\n",
    "        missing.append(var)\n",
    "\n",
    "if missing:\n",
    "    raise EnvironmentError(f\"âŒ Faltan variables: {missing}\")\n",
    "\n",
    "print(\"\\nâœ… Variables configuradas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5046d0d-b3c2-41d5-8918-1171e535e605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SesiÃ³n AWS creada\n",
      "   Account ID: 020635523025\n",
      "   Region: us-west-1\n",
      "\n",
      "âœ… S3 configurado: xideralaws-curso-fernanda\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 3: CREAR SESIÃ“N AWS SEGURA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def get_aws_session():\n",
    "    \"\"\"Crea sesiÃ³n AWS segura con validaciÃ³n\"\"\"\n",
    "    try:\n",
    "        session = boto3.Session(\n",
    "            aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "            aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "            region_name=os.getenv('AWS_DEFAULT_REGION')\n",
    "        )\n",
    "        \n",
    "        # Verificar credenciales con STS\n",
    "        sts = session.client('sts')\n",
    "        identity = sts.get_caller_identity()\n",
    "        \n",
    "        print(\"âœ… SesiÃ³n AWS creada\")\n",
    "        print(f\"   Account ID: {identity['Account']}\")\n",
    "        print(f\"   Region: {session.region_name}\")\n",
    "        \n",
    "        return session\n",
    "    \n",
    "    except NoCredentialsError:\n",
    "        raise Exception(\"âŒ Credenciales AWS no encontradas\")\n",
    "    except ClientError as e:\n",
    "        raise Exception(f\"âŒ Error de autenticaciÃ³n: {e}\")\n",
    "\n",
    "# Crear sesiÃ³n y clientes\n",
    "aws_session = get_aws_session()\n",
    "s3_client = aws_session.client('s3')\n",
    "\n",
    "# ConfiguraciÃ³n S3\n",
    "S3_BUCKET = os.getenv('S3_BUCKET_NAME')\n",
    "S3_RAW_PREFIX = 'disney-project/raw'\n",
    "S3_CLEANED_PREFIX = 'disney-project/cleaned'\n",
    "S3_FINAL_PREFIX = 'disney-project/final'\n",
    "\n",
    "print(f\"\\nâœ… S3 configurado: {S3_BUCKET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7410b7-e460-4d1d-8006-2229de80f14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FunciÃ³n upload_to_s3 definida\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 4: FUNCIÃ“N PARA SUBIR ARCHIVOS A S3\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def upload_to_s3(local_file, s3_key):\n",
    "    \"\"\"Sube archivo a S3 con encriptaciÃ³n\"\"\"\n",
    "    try:\n",
    "        s3_client.upload_file(\n",
    "            Filename=local_file,\n",
    "            Bucket=S3_BUCKET,\n",
    "            Key=s3_key,\n",
    "            ExtraArgs={'ServerSideEncryption': 'AES256'}\n",
    "        )\n",
    "        return f\"âœ… Subido: s3://{S3_BUCKET}/{s3_key}\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error: {e}\"\n",
    "\n",
    "print(\"âœ… FunciÃ³n upload_to_s3 definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0c5a2d-114b-417d-9a88-9bc415c9ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Iniciando Spark Session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/17 19:44:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark Session creada\n",
      "   VersiÃ³n: 4.0.1\n",
      "   App Name: Disney Data Pipeline - Fase 3\n",
      "   Master: local[*]\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 5: CREAR SPARK SESSION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ”¥ Iniciando Spark Session...\\n\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Disney Data Pipeline - Fase 3\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"âœ… Spark Session creada\")\n",
    "print(f\"   VersiÃ³n: {spark.version}\")\n",
    "print(f\"   App Name: {spark.sparkContext.appName}\")\n",
    "print(f\"   Master: {spark.sparkContext.master}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bd70c1-c83d-472b-a3f9-b1f56c82981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Cargando datos de Fase 2...\n",
      "\n",
      "================================================================================\n",
      "âœ… Pickle cargado\n",
      "\n",
      "ğŸ“‹ Contenido:\n",
      "   - df_movies_clean\n",
      "   - df_characters_clean\n",
      "   - df_relations\n",
      "   - metadata\n",
      "\n",
      "âœ… DataFrames extraÃ­dos:\n",
      "   ğŸ¬ PelÃ­culas: 119 registros, 19 columnas\n",
      "   ğŸ‘¥ Personajes: 1,419 registros, 16 columnas\n",
      "   ğŸ”— Relaciones: 1,068 registros, 3 columnas\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 6: CARGAR DATOS DE FASE 2\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ“¦ Cargando datos de Fase 2...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Verificar que existe\n",
    "if not Path('datos_fase2.pkl').exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ No se encontrÃ³ 'datos_fase2.pkl'\\n\"\n",
    "        \"   Ejecuta primero: 02_limpieza_transformacion.ipynb\"\n",
    "    )\n",
    "\n",
    "# Cargar pickle\n",
    "with open('datos_fase2.pkl', 'rb') as f:\n",
    "    datos_fase2 = pickle.load(f)\n",
    "\n",
    "print(\"âœ… Pickle cargado\")\n",
    "print(f\"\\nğŸ“‹ Contenido:\")\n",
    "for key in datos_fase2.keys():\n",
    "    print(f\"   - {key}\")\n",
    "\n",
    "# Extraer DataFrames\n",
    "df_movies_pandas = datos_fase2['df_movies_clean']\n",
    "df_characters_pandas = datos_fase2['df_characters_clean']\n",
    "df_relations_pandas = datos_fase2['df_relations']\n",
    "\n",
    "print(f\"\\nâœ… DataFrames extraÃ­dos:\")\n",
    "print(f\"   ğŸ¬ PelÃ­culas: {len(df_movies_pandas):,} registros, {len(df_movies_pandas.columns)} columnas\")\n",
    "print(f\"   ğŸ‘¥ Personajes: {len(df_characters_pandas):,} registros, {len(df_characters_pandas.columns)} columnas\")\n",
    "print(f\"   ğŸ”— Relaciones: {len(df_relations_pandas):,} registros, {len(df_relations_pandas.columns)} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f2454aa-340c-4d0c-902a-05c8c6ca2c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Convirtiendo a Spark DataFrames...\n",
      "\n",
      "1ï¸âƒ£ Convirtiendo pelÃ­culas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… 119 registros\n",
      "   Columnas: 19\n",
      "\n",
      "2ï¸âƒ£ Convirtiendo personajes...\n",
      "   âš ï¸  Columnas con tipos complejos: ['films', 'shortFilms', 'tvShows', 'videoGames', 'parkAttractions', 'allies', 'enemies']\n",
      "   ğŸ“ Convirtiendo a string...\n",
      "   âœ… 1,419 registros\n",
      "   Columnas: 16\n",
      "\n",
      "3ï¸âƒ£ Convirtiendo relaciones...\n",
      "   âœ… 1,068 registros\n",
      "\n",
      "âœ… ConversiÃ³n completada exitosamente\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 7: CONVERTIR PANDAS â†’ SPARK DATAFRAMES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"âš¡ Convirtiendo a Spark DataFrames...\\n\")\n",
    "\n",
    "# ============================================\n",
    "# 1. PELÃCULAS\n",
    "# ============================================\n",
    "print(\"1ï¸âƒ£ Convirtiendo pelÃ­culas...\")\n",
    "spark_movies = spark.createDataFrame(df_movies_pandas)\n",
    "print(f\"   âœ… {spark_movies.count():,} registros\")\n",
    "print(f\"   Columnas: {len(spark_movies.columns)}\")\n",
    "\n",
    "# ============================================\n",
    "# 2. PERSONAJES (con manejo de tipos complejos)\n",
    "# ============================================\n",
    "print(\"\\n2ï¸âƒ£ Convirtiendo personajes...\")\n",
    "\n",
    "# Identificar columnas problemÃ¡ticas (listas, objetos complejos)\n",
    "problematic_cols = []\n",
    "for col in df_characters_pandas.columns:\n",
    "    sample = df_characters_pandas[col].iloc[0]\n",
    "    if isinstance(sample, (list, dict)):\n",
    "        problematic_cols.append(col)\n",
    "\n",
    "if problematic_cols:\n",
    "    print(f\"   âš ï¸  Columnas con tipos complejos: {problematic_cols}\")\n",
    "    print(f\"   ğŸ“ Convirtiendo a string...\")\n",
    "    \n",
    "    # Crear copia para modificar\n",
    "    df_chars_clean = df_characters_pandas.copy()\n",
    "    \n",
    "    # Convertir columnas problemÃ¡ticas a string\n",
    "    for col in problematic_cols:\n",
    "        df_chars_clean[col] = df_chars_clean[col].astype(str)\n",
    "    \n",
    "    # Crear DataFrame Spark con datos limpios\n",
    "    spark_characters = spark.createDataFrame(df_chars_clean)\n",
    "else:\n",
    "    # No hay problemas, conversiÃ³n directa\n",
    "    spark_characters = spark.createDataFrame(df_characters_pandas)\n",
    "\n",
    "print(f\"   âœ… {spark_characters.count():,} registros\")\n",
    "print(f\"   Columnas: {len(spark_characters.columns)}\")\n",
    "\n",
    "# ============================================\n",
    "# 3. RELACIONES\n",
    "# ============================================\n",
    "if not df_relations_pandas.empty:\n",
    "    print(\"\\n3ï¸âƒ£ Convirtiendo relaciones...\")\n",
    "    spark_relations = spark.createDataFrame(df_relations_pandas)\n",
    "    print(f\"   âœ… {spark_relations.count():,} registros\")\n",
    "else:\n",
    "    print(\"\\n3ï¸âƒ£ Sin relaciones para convertir\")\n",
    "    spark_relations = None\n",
    "\n",
    "print(\"\\nâœ… ConversiÃ³n completada exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bbb491e-f26b-41a1-a04d-02959778d434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ CREANDO VISTAS SQL TEMPORALES\n",
      "\n",
      "================================================================================\n",
      "âœ… Vistas SQL creadas:\n",
      "   - movies\n",
      "   - characters\n",
      "   - relations\n",
      "\n",
      "ğŸ“‹ Esquema de pelÃ­culas:\n",
      "root\n",
      " |-- film_title: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- box_office_revenue: string (nullable = true)\n",
      " |-- opening_revenue: string (nullable = true)\n",
      " |-- release_date: timestamp (nullable = true)\n",
      " |-- opening_revenue_over_total_revenue: long (nullable = true)\n",
      " |-- imdb_score: double (nullable = true)\n",
      " |-- rt_critics_score: long (nullable = true)\n",
      " |-- rt_audience_score: long (nullable = true)\n",
      " |-- release_year: long (nullable = true)\n",
      " |-- release_month: long (nullable = true)\n",
      " |-- release_quarter: long (nullable = true)\n",
      " |-- release_day_of_week: string (nullable = true)\n",
      " |-- box_office_revenue_clean: double (nullable = true)\n",
      " |-- decade: long (nullable = true)\n",
      " |-- decade_label: string (nullable = true)\n",
      " |-- rating_category: string (nullable = true)\n",
      " |-- segment: string (nullable = true)\n",
      " |-- film_title_clean: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 8: CREAR VISTAS SQL TEMPORALES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ“‹ CREANDO VISTAS SQL TEMPORALES\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Registrar DataFrames como tablas SQL\n",
    "spark_movies.createOrReplaceTempView(\"movies\")\n",
    "spark_characters.createOrReplaceTempView(\"characters\")\n",
    "if spark_relations is not None:\n",
    "    spark_relations.createOrReplaceTempView(\"relations\")\n",
    "\n",
    "print(\"âœ… Vistas SQL creadas:\")\n",
    "print(\"   - movies\")\n",
    "print(\"   - characters\")\n",
    "if spark_relations is not None:\n",
    "    print(\"   - relations\")\n",
    "\n",
    "# Mostrar esquema de pelÃ­culas\n",
    "print(\"\\nğŸ“‹ Esquema de pelÃ­culas:\")\n",
    "spark_movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641a3290-d796-4fe8-9587-4c9ff3a3f61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ ANÃLISIS DISTRIBUIDO CON SPARK SQL\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ’° TOP 10 PELÃCULAS POR REVENUE:\n",
      "--------------------------------------------------------------------------------\n",
      "+------------------------------------------+------------+----------------+-------------------------+\n",
      "|film_title                                |release_year|revenue_millions|segment                  |\n",
      "+------------------------------------------+------------+----------------+-------------------------+\n",
      "|Star Wars: Episode VII - The Force Awakens|2015        |936.66          |Ã‰xito CrÃ­tico y Comercial|\n",
      "|Avengers: Endgame                         |2019        |858.37          |Ã‰xito CrÃ­tico y Comercial|\n",
      "|Spider-Man: No Way Home                   |2021        |804.79          |Ã‰xito CrÃ­tico y Comercial|\n",
      "|Black Panther                             |2018        |700.06          |Ã‰xito CrÃ­tico y Comercial|\n",
      "|Avengers: Infinity War                    |2018        |678.82          |Ã‰xito CrÃ­tico y Comercial|\n",
      "|The Avengers                              |2012        |623.36          |Ã‰xito CrÃ­tico y Comercial|\n",
      "|Star Wars: Episode VIII - The Last Jedi   |2017        |620.18          |Ã‰xito Comercial          |\n",
      "|Incredibles 2                             |2018        |608.58          |Ã‰xito CrÃ­tico y Comercial|\n",
      "|The Lion King                             |2019        |543.64          |Ã‰xito Comercial          |\n",
      "|Rogue One: A Star Wars Story              |2016        |532.18          |Ã‰xito CrÃ­tico y Comercial|\n",
      "+------------------------------------------+------------+----------------+-------------------------+\n",
      "\n",
      "\n",
      "ğŸ“… ANÃLISIS POR DÃ‰CADA:\n",
      "--------------------------------------------------------------------------------\n",
      "+------------+----------+--------------------+----------------------+\n",
      "|decade_label|num_movies|avg_revenue_millions|total_revenue_millions|\n",
      "+------------+----------+--------------------+----------------------+\n",
      "|1980s       |1         |111.54              |111.54                |\n",
      "|1990s       |14        |159.1               |2227.35               |\n",
      "|2000s       |21        |145.41              |3053.68               |\n",
      "|2010s       |63        |320.14              |20169.01              |\n",
      "|2020s       |20        |219.49              |4389.74               |\n",
      "+------------+----------+--------------------+----------------------+\n",
      "\n",
      "\n",
      "ğŸŒŸ TOP 10 PERSONAJES MÃS POPULARES:\n",
      "--------------------------------------------------------------------------------\n",
      "+--------------+-----------------+---------+------------+-------------------+\n",
      "|name          |total_appearances|num_films|num_tv_shows|popularity_category|\n",
      "+--------------+-----------------+---------+------------+-------------------+\n",
      "|Chip and Dale |23               |6        |17          |Alta               |\n",
      "|Clarabelle Cow|20               |4        |16          |Alta               |\n",
      "|Big Bad Wolf  |16               |3        |13          |Alta               |\n",
      "|JosÃ© Carioca  |16               |6        |10          |Alta               |\n",
      "|Ariel         |14               |8        |6           |Media              |\n",
      "|Bigfoot       |14               |4        |10          |Media              |\n",
      "|Captain Hook  |12               |6        |6           |Media              |\n",
      "|Jiminy Cricket|12               |5        |7           |Media              |\n",
      "|Beagle Boys   |11               |2        |9           |Media              |\n",
      "|Br'er Bear    |11               |6        |5           |Media              |\n",
      "+--------------+-----------------+---------+------------+-------------------+\n",
      "\n",
      "\n",
      "âœ… AnÃ¡lisis SQL completado\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 9: ANÃLISIS CON SPARK SQL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"âš¡ ANÃLISIS DISTRIBUIDO CON SPARK SQL\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================\n",
    "# QUERY 1: Top 10 pelÃ­culas por revenue\n",
    "# ============================================\n",
    "print(\"\\nğŸ’° TOP 10 PELÃCULAS POR REVENUE:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "top_revenue = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        film_title,\n",
    "        release_year,\n",
    "        ROUND(box_office_revenue_clean/1000000, 2) as revenue_millions,\n",
    "        segment\n",
    "    FROM movies\n",
    "    WHERE box_office_revenue_clean IS NOT NULL\n",
    "    ORDER BY box_office_revenue_clean DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "top_revenue.show(10, truncate=False)\n",
    "\n",
    "# ============================================\n",
    "# QUERY 2: AnÃ¡lisis por dÃ©cada\n",
    "# ============================================\n",
    "print(\"\\nğŸ“… ANÃLISIS POR DÃ‰CADA:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "decade_analysis = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        decade_label,\n",
    "        COUNT(*) as num_movies,\n",
    "        ROUND(AVG(box_office_revenue_clean)/1000000, 2) as avg_revenue_millions,\n",
    "        ROUND(SUM(box_office_revenue_clean)/1000000, 2) as total_revenue_millions\n",
    "    FROM movies\n",
    "    WHERE decade_label IS NOT NULL\n",
    "    GROUP BY decade_label\n",
    "    ORDER BY decade_label\n",
    "\"\"\")\n",
    "\n",
    "decade_analysis.show(truncate=False)\n",
    "\n",
    "# ============================================\n",
    "# QUERY 3: Top personajes\n",
    "# ============================================\n",
    "print(\"\\nğŸŒŸ TOP 10 PERSONAJES MÃS POPULARES:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "top_characters = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        name,\n",
    "        total_appearances,\n",
    "        num_films,\n",
    "        num_tv_shows,\n",
    "        popularity_category\n",
    "    FROM characters\n",
    "    WHERE total_appearances > 0\n",
    "    ORDER BY total_appearances DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "top_characters.show(10, truncate=False)\n",
    "\n",
    "print(\"\\nâœ… AnÃ¡lisis SQL completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3513981d-ec5d-417c-b615-8c2b565fddb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— REALIZANDO JOIN DISTRIBUIDO\n",
      "\n",
      "================================================================================\n",
      "1ï¸âƒ£ Contando personajes por pelÃ­cula...\n",
      "   âœ… 366 pelÃ­culas con personajes identificados\n",
      "\n",
      "2ï¸âƒ£ Realizando JOIN...\n",
      "   âœ… JOIN completado: 119 registros\n",
      "\n",
      "3ï¸âƒ£ Top 15 pelÃ­culas con mÃ¡s personajes:\n",
      "--------------------------------------------------------------------------------\n",
      "+-------------------------------+------------+------------+---------------+\n",
      "|film_title                     |release_year|revenue     |character_count|\n",
      "+-------------------------------+------------+------------+---------------+\n",
      "|Ralph Breaks the Internet      |2018        |2.01091711E8|19             |\n",
      "|Alice Through the Looking Glass|2016        |7.7041381E7 |7              |\n",
      "|The Jungle Book                |2016        |3.64001123E8|7              |\n",
      "|Fantasia 2000                  |2000        |6.065542E7  |7              |\n",
      "|Tangled                        |2010        |2.00821936E8|7              |\n",
      "|Zootopia                       |2016        |3.41268248E8|6              |\n",
      "|Home on the Range              |2004        |5.0030461E7 |6              |\n",
      "|Big Hero 6                     |2014        |2.22527828E8|6              |\n",
      "|Planes: Fire & Rescue          |2014        |5.9165787E7 |5              |\n",
      "|Treasure Planet                |2002        |3.8176783E7 |5              |\n",
      "|Planes                         |2013        |9.0288712E7 |5              |\n",
      "|The Hunchback of Notre Dame    |1996        |1.00138851E8|4              |\n",
      "|Toy Story 4                    |2019        |4.34038008E8|4              |\n",
      "|Frozen II                      |2019        |4.77373578E8|4              |\n",
      "|The Emperor's New Groove       |2000        |8.9302687E7 |3              |\n",
      "+-------------------------------+------------+------------+---------------+\n",
      "only showing top 15 rows\n",
      "\n",
      "âœ… Dataset enriquecido creado\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 10: JOIN DISTRIBUIDO - PELÃCULAS CON PERSONAJES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ”— REALIZANDO JOIN DISTRIBUIDO\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if spark_relations is not None:\n",
    "    # Paso 1: Contar personajes por pelÃ­cula\n",
    "    print(\"1ï¸âƒ£ Contando personajes por pelÃ­cula...\")\n",
    "    \n",
    "    char_count = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            movie_title_clean,\n",
    "            COUNT(DISTINCT character_name) as character_count\n",
    "        FROM relations\n",
    "        GROUP BY movie_title_clean\n",
    "    \"\"\")\n",
    "    \n",
    "    print(f\"   âœ… {char_count.count()} pelÃ­culas con personajes identificados\\n\")\n",
    "    \n",
    "    # Paso 2: JOIN con dataset de pelÃ­culas\n",
    "    print(\"2ï¸âƒ£ Realizando JOIN...\")\n",
    "    \n",
    "    movies_enriched = spark_movies.join(\n",
    "        char_count,\n",
    "        spark_movies['film_title_clean'] == char_count['movie_title_clean'],\n",
    "        how='left'\n",
    "    ).select(\n",
    "        spark_movies['*'],\n",
    "        F.coalesce(char_count['character_count'], F.lit(0)).alias('character_count')\n",
    "    )\n",
    "    \n",
    "    print(f\"   âœ… JOIN completado: {movies_enriched.count():,} registros\\n\")\n",
    "    \n",
    "    # Mostrar pelÃ­culas con mÃ¡s personajes\n",
    "    print(\"3ï¸âƒ£ Top 15 pelÃ­culas con mÃ¡s personajes:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    movies_enriched.select(\n",
    "        'film_title',\n",
    "        'release_year',\n",
    "        F.col('box_office_revenue_clean').alias('revenue'),\n",
    "        'character_count'\n",
    "    ).orderBy(F.col('character_count').desc()).show(15, truncate=False)\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸  No hay relaciones disponibles\")\n",
    "    movies_enriched = spark_movies.withColumn('character_count', F.lit(0))\n",
    "\n",
    "print(\"\\nâœ… Dataset enriquecido creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f097424e-2b78-4f66-ba22-fcab581ffd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š AGREGACIONES POR SEGMENTO\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ MÃ‰TRICAS POR SEGMENTO:\n",
      "+-------------------------+----------+---------------+--------------+--------------+\n",
      "|segment                  |num_movies|total_revenue  |avg_revenue   |avg_characters|\n",
      "+-------------------------+----------+---------------+--------------+--------------+\n",
      "|Ã‰xito CrÃ­tico y Comercial|30        |1.4382616427E10|4.7942054757E8|1.0           |\n",
      "|Ã‰xito CrÃ­tico            |43        |7.439824875E9  |1.7301918314E8|1.5           |\n",
      "|Bajo Rendimiento         |38        |4.512640573E9  |1.1875369929E8|1.2           |\n",
      "|Ã‰xito Comercial          |8         |3.61623254E9   |4.520290675E8 |0.9           |\n",
      "+-------------------------+----------+---------------+--------------+--------------+\n",
      "\n",
      "\n",
      "âœ… AgregaciÃ³n completada: 4 segmentos\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 11: AGREGACIONES POR SEGMENTO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ“Š AGREGACIONES POR SEGMENTO\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# AgregaciÃ³n por segmento\n",
    "agg_by_segment = movies_enriched.groupBy('segment').agg(\n",
    "    F.count('*').alias('num_movies'),\n",
    "    F.round(F.sum('box_office_revenue_clean'), 2).alias('total_revenue'),\n",
    "    F.round(F.avg('box_office_revenue_clean'), 2).alias('avg_revenue'),\n",
    "    F.round(F.avg('character_count'), 1).alias('avg_characters')\n",
    ").orderBy(F.col('total_revenue').desc())\n",
    "\n",
    "print(\"ğŸ¯ MÃ‰TRICAS POR SEGMENTO:\")\n",
    "agg_by_segment.show(truncate=False)\n",
    "\n",
    "# Convertir a Pandas\n",
    "df_segment_agg = agg_by_segment.toPandas()\n",
    "\n",
    "print(f\"\\nâœ… AgregaciÃ³n completada: {len(df_segment_agg)} segmentos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "267e7237-800e-4741-bbea-fa8776a16871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… AGREGACIONES TEMPORALES\n",
      "\n",
      "================================================================================\n",
      "1ï¸âƒ£ Agregando por aÃ±o...\n",
      "âœ… 33 aÃ±os procesados\n",
      "\n",
      "ğŸ“Š Datos por aÃ±o (2000+):\n",
      "+------------+----------+--------------+-------------+--------------+\n",
      "|release_year|num_movies|avg_revenue   |total_revenue|avg_characters|\n",
      "+------------+----------+--------------+-------------+--------------+\n",
      "|2000        |3         |7.230504433E7 |2.16915133E8 |4.0           |\n",
      "|2001        |2         |1.69964861E8  |3.39929722E8 |0.5           |\n",
      "|2002        |2         |9.19855605E7  |1.83971121E8 |3.0           |\n",
      "|2003        |2         |2.125256275E8 |4.25051255E8 |1.0           |\n",
      "|2004        |2         |1.557357765E8 |3.11471553E8 |3.0           |\n",
      "|2005        |2         |7.74323855E7  |1.54864771E8 |0.0           |\n",
      "|2006        |1         |2.44082982E8  |2.44082982E8 |0.0           |\n",
      "|2007        |2         |1.521339125E8 |3.04267825E8 |1.0           |\n",
      "|2008        |2         |1.689308715E8 |3.37861743E8 |0.0           |\n",
      "|2009        |3         |1.7842030867E8|5.35260926E8 |1.3           |\n",
      "|2010        |4         |3.1561281425E8|1.262451257E9|2.8           |\n",
      "|2011        |5         |1.194446258E8 |5.97223129E8 |0.2           |\n",
      "|2012        |4         |2.713387685E8 |1.085355074E9|0.5           |\n",
      "|2013        |6         |2.6830124067E8|1.609807444E9|1.8           |\n",
      "|2014        |5         |2.23209433E8  |1.116047165E9|2.2           |\n",
      "|2015        |6         |3.7609507333E8|2.25657044E9 |0.7           |\n",
      "|2016        |9         |3.0738890011E8|2.766500101E9|2.3           |\n",
      "|2017        |7         |3.6094702957E8|2.526629207E9|0.1           |\n",
      "|2018        |7         |3.8831139957E8|2.718179797E9|2.9           |\n",
      "|2019        |10        |4.230242223E8 |4.230242223E9|1.2           |\n",
      "|2020        |1         |6.1555145E7   |6.1555145E7  |0.0           |\n",
      "|2021        |7         |2.3068264943E8|1.614778546E9|0.4           |\n",
      "|2022        |5         |2.729387296E8 |1.364693648E9|0.2           |\n",
      "|2023        |7         |1.9267261E8   |1.34870827E9 |0.3           |\n",
      "+------------+----------+--------------+-------------+--------------+\n",
      "\n",
      "âœ… Pandas: 33 registros\n",
      "\n",
      "2ï¸âƒ£ Agregando por dÃ©cada...\n",
      "âœ… 5 dÃ©cadas procesadas\n",
      "\n",
      "ğŸ“Š Datos por dÃ©cada:\n",
      "+------------+----------+--------------+---------------+\n",
      "|decade_label|num_movies|avg_revenue   |total_revenue  |\n",
      "+------------+----------+--------------+---------------+\n",
      "|1980s       |1         |1.11543479E8  |1.11543479E8   |\n",
      "|1990s       |14        |1.5909660421E8|2.227352459E9  |\n",
      "|2000s       |21        |1.4541319195E8|3.053677031E9  |\n",
      "|2010s       |63        |3.2014294979E8|2.0169005837E10|\n",
      "|2020s       |20        |2.1948678045E8|4.389735609E9  |\n",
      "+------------+----------+--------------+---------------+\n",
      "\n",
      "âœ… Pandas: 5 registros\n",
      "\n",
      "âœ… CELDA 12 COMPLETADA\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 12: AGREGACIONES TEMPORALES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ“… AGREGACIONES TEMPORALES\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================\n",
    "# Por AÃ‘O\n",
    "# ============================================\n",
    "print(\"1ï¸âƒ£ Agregando por aÃ±o...\")\n",
    "\n",
    "agg_by_year = movies_enriched.groupBy('release_year').agg(\n",
    "    F.count('*').alias('num_movies'),\n",
    "    F.round(F.avg('box_office_revenue_clean'), 2).alias('avg_revenue'),\n",
    "    F.round(F.sum('box_office_revenue_clean'), 2).alias('total_revenue'),\n",
    "    F.round(F.avg('character_count'), 1).alias('avg_characters')\n",
    ").orderBy('release_year')\n",
    "\n",
    "print(f\"âœ… {agg_by_year.count()} aÃ±os procesados\")\n",
    "\n",
    "# Mostrar datos\n",
    "print(\"\\nğŸ“Š Datos por aÃ±o (2000+):\")\n",
    "agg_by_year.filter(F.col('release_year') >= 2000).show(25, truncate=False)\n",
    "\n",
    "# Convertir a Pandas\n",
    "df_year_agg = agg_by_year.toPandas()\n",
    "print(f\"âœ… Pandas: {len(df_year_agg)} registros\\n\")\n",
    "\n",
    "# ============================================\n",
    "# Por DÃ‰CADA\n",
    "# ============================================\n",
    "print(\"2ï¸âƒ£ Agregando por dÃ©cada...\")\n",
    "\n",
    "# Verificar si existe decade_label\n",
    "if 'decade_label' in movies_enriched.columns:\n",
    "    decade_col = 'decade_label'\n",
    "else:\n",
    "    print(\"   âš ï¸  Creando columna decade...\")\n",
    "    movies_enriched = movies_enriched.withColumn(\n",
    "        'decade',\n",
    "        F.floor(F.col('release_year') / 10) * 10\n",
    "    )\n",
    "    decade_col = 'decade'\n",
    "\n",
    "agg_by_decade = movies_enriched.groupBy(decade_col).agg(\n",
    "    F.count('*').alias('num_movies'),\n",
    "    F.round(F.avg('box_office_revenue_clean'), 2).alias('avg_revenue'),\n",
    "    F.round(F.sum('box_office_revenue_clean'), 2).alias('total_revenue')\n",
    ").orderBy(decade_col)\n",
    "\n",
    "print(f\"âœ… {agg_by_decade.count()} dÃ©cadas procesadas\")\n",
    "\n",
    "# Mostrar datos\n",
    "print(\"\\nğŸ“Š Datos por dÃ©cada:\")\n",
    "agg_by_decade.show(truncate=False)\n",
    "\n",
    "# Convertir a Pandas\n",
    "df_decade_agg = agg_by_decade.toPandas()\n",
    "print(f\"âœ… Pandas: {len(df_decade_agg)} registros\")\n",
    "\n",
    "print(\"\\nâœ… CELDA 12 COMPLETADA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "863d6269-83c1-43f4-80dd-07d9542ab025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ GUARDANDO ARCHIVOS PARQUET\n",
      "\n",
      "================================================================================\n",
      "1ï¸âƒ£ Guardando movies_enriched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Guardado\n",
      "\n",
      "2ï¸âƒ£ Guardando agg_by_segment...\n",
      "   âœ… Guardado\n",
      "\n",
      "3ï¸âƒ£ Guardando agg_temporal...\n",
      "   âœ… Guardado\n",
      "\n",
      "4ï¸âƒ£ Guardando agg_decade...\n",
      "   âœ… Guardado\n",
      "\n",
      "âœ… Todos los archivos Parquet guardados en: ./spark_output/\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 13: GUARDAR EN FORMATO PARQUET\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ’¾ GUARDANDO ARCHIVOS PARQUET\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "Path('./spark_output').mkdir(exist_ok=True)\n",
    "\n",
    "print(\"1ï¸âƒ£ Guardando movies_enriched...\")\n",
    "movies_enriched.write.mode('overwrite').parquet('./spark_output/movies_enriched.parquet')\n",
    "print(\"   âœ… Guardado\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ Guardando agg_by_segment...\")\n",
    "agg_by_segment.write.mode('overwrite').parquet('./spark_output/agg_segment.parquet')\n",
    "print(\"   âœ… Guardado\")\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ Guardando agg_temporal...\")\n",
    "agg_by_year.write.mode('overwrite').parquet('./spark_output/agg_temporal.parquet')\n",
    "print(\"   âœ… Guardado\")\n",
    "\n",
    "print(\"\\n4ï¸âƒ£ Guardando agg_decade...\")\n",
    "agg_by_decade.write.mode('overwrite').parquet('./spark_output/agg_decade.parquet')\n",
    "print(\"   âœ… Guardado\")\n",
    "\n",
    "print(\"\\nâœ… Todos los archivos Parquet guardados en: ./spark_output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "897e51c1-ea0e-49c1-b028-e1278ce1ae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â˜ï¸  EXPORTANDO A CSV Y SUBIENDO A S3\n",
      "\n",
      "================================================================================\n",
      "1ï¸âƒ£ Exportando movies_enriched...\n",
      "   âœ… Subido: s3://xideralaws-curso-fernanda/disney-project/final/movies_spark.csv\n",
      "\n",
      "2ï¸âƒ£ Exportando agg_segment...\n",
      "   âœ… Subido: s3://xideralaws-curso-fernanda/disney-project/final/agg_segment.csv\n",
      "\n",
      "3ï¸âƒ£ Exportando agg_temporal...\n",
      "   âœ… Subido: s3://xideralaws-curso-fernanda/disney-project/final/agg_temporal.csv\n",
      "\n",
      "4ï¸âƒ£ Exportando agg_decade...\n",
      "   âœ… Subido: s3://xideralaws-curso-fernanda/disney-project/final/agg_decade.csv\n",
      "\n",
      "ğŸ‰ Todos los archivos subidos a S3\n",
      "   UbicaciÃ³n: s3://xideralaws-curso-fernanda/disney-project/final/\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 14: CONVERTIR A CSV Y SUBIR A S3\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"â˜ï¸  EXPORTANDO A CSV Y SUBIENDO A S3\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "Path('./data/final').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1. Movies enriched\n",
    "print(\"1ï¸âƒ£ Exportando movies_enriched...\")\n",
    "df_movies_final = movies_enriched.toPandas()\n",
    "movies_csv = './data/final/movies_spark.csv'\n",
    "df_movies_final.to_csv(movies_csv, index=False, encoding='utf-8')\n",
    "result = upload_to_s3(movies_csv, f'{S3_FINAL_PREFIX}/movies_spark.csv')\n",
    "print(f\"   {result}\")\n",
    "\n",
    "# 2. Segment\n",
    "print(\"\\n2ï¸âƒ£ Exportando agg_segment...\")\n",
    "segment_csv = './data/final/agg_segment.csv'\n",
    "df_segment_agg.to_csv(segment_csv, index=False, encoding='utf-8')\n",
    "result = upload_to_s3(segment_csv, f'{S3_FINAL_PREFIX}/agg_segment.csv')\n",
    "print(f\"   {result}\")\n",
    "\n",
    "# 3. Temporal\n",
    "print(\"\\n3ï¸âƒ£ Exportando agg_temporal...\")\n",
    "temporal_csv = './data/final/agg_temporal.csv'\n",
    "df_year_agg.to_csv(temporal_csv, index=False, encoding='utf-8')\n",
    "result = upload_to_s3(temporal_csv, f'{S3_FINAL_PREFIX}/agg_temporal.csv')\n",
    "print(f\"   {result}\")\n",
    "\n",
    "# 4. Decade\n",
    "print(\"\\n4ï¸âƒ£ Exportando agg_decade...\")\n",
    "decade_csv = './data/final/agg_decade.csv'\n",
    "df_decade_agg.to_csv(decade_csv, index=False, encoding='utf-8')\n",
    "result = upload_to_s3(decade_csv, f'{S3_FINAL_PREFIX}/agg_decade.csv')\n",
    "print(f\"   {result}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Todos los archivos subidos a S3\")\n",
    "print(f\"   UbicaciÃ³n: s3://{S3_BUCKET}/{S3_FINAL_PREFIX}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd6415a3-cf52-4baf-902c-141453c979a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ PREPARANDO DATOS PARA DASHBOARD\n",
      "\n",
      "================================================================================\n",
      "âœ… Datos guardados en: datos_fase3.pkl\n",
      "   PelÃ­culas: 119\n",
      "   Personajes: 1419\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 15: GUARDAR DATOS PARA DASHBOARD\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸ’¾ PREPARANDO DATOS PARA DASHBOARD\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "datos_fase3 = {\n",
    "    'df_movies_dashboard': df_movies_final,\n",
    "    'df_characters_final': df_characters_pandas,\n",
    "    'segment_analysis': df_segment_agg,\n",
    "    'temporal_analysis': df_year_agg,\n",
    "    'decade_analysis': df_decade_agg,\n",
    "    'rankings': {\n",
    "        'top_revenue': df_movies_final.nlargest(10, 'box_office_revenue_clean'),\n",
    "    },\n",
    "    'metadata': {\n",
    "        'movies_count': len(df_movies_final),\n",
    "        'characters_count': len(df_characters_pandas),\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'notebook': '03b_procesamiento_spark.ipynb',\n",
    "        'spark_version': spark.version,\n",
    "        'status': 'SUCCESS'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('datos_fase3.pkl', 'wb') as f:\n",
    "    pickle.dump(datos_fase3, f)\n",
    "\n",
    "print(\"âœ… Datos guardados en: datos_fase3.pkl\")\n",
    "print(f\"   PelÃ­culas: {datos_fase3['metadata']['movies_count']}\")\n",
    "print(f\"   Personajes: {datos_fase3['metadata']['characters_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b683edc-c664-4aa6-8124-787483cd3392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ‰ PROCESAMIENTO SPARK COMPLETADO\n",
      "======================================================================\n",
      "\n",
      "âš¡ SPARK PROCESSING:\n",
      "   VersiÃ³n: 4.0.1\n",
      "   PelÃ­culas: 119\n",
      "   Personajes: 1,419\n",
      "   Relaciones: 1,068\n",
      "\n",
      "ğŸ“Š ARCHIVOS GENERADOS:\n",
      "   Parquet: ./spark_output/ (4 archivos)\n",
      "   CSV + S3: s3://xideralaws-curso-fernanda/disney-project/final/ (4 archivos)\n",
      "   Pickle: datos_fase3.pkl\n",
      "\n",
      "ğŸš€ SIGUIENTE PASO:\n",
      "   Ejecutar: streamlit run dashboard_disney.py\n",
      "======================================================================\n",
      "\n",
      "âœ… Spark Session cerrada\n",
      "âœ… Notebook 03b completado al 100%\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 16: RESUMEN FINAL Y CERRAR SPARK\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ PROCESAMIENTO SPARK COMPLETADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nâš¡ SPARK PROCESSING:\")\n",
    "print(f\"   VersiÃ³n: {spark.version}\")\n",
    "print(f\"   PelÃ­culas: {movies_enriched.count():,}\")\n",
    "print(f\"   Personajes: {spark_characters.count():,}\")\n",
    "if spark_relations:\n",
    "    print(f\"   Relaciones: {spark_relations.count():,}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ARCHIVOS GENERADOS:\")\n",
    "print(f\"   Parquet: ./spark_output/ (4 archivos)\")\n",
    "print(f\"   CSV + S3: s3://{S3_BUCKET}/{S3_FINAL_PREFIX}/ (4 archivos)\")\n",
    "print(f\"   Pickle: datos_fase3.pkl\")\n",
    "\n",
    "print(f\"\\nğŸš€ SIGUIENTE PASO:\")\n",
    "print(f\"   Ejecutar: streamlit run dashboard_disney.py\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "spark.stop()\n",
    "print(\"\\nâœ… Spark Session cerrada\")\n",
    "print(\"âœ… Notebook 03b completado al 100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec06a5-e3e6-4c03-984f-49c001cd3d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
